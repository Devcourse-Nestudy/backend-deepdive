## 데이터베이스 인덱스로 B-트리가 사용되는 이유

데이터베이스 성능 최적화에 있어 인덱스는 필수적인 요소로 자리 잡고 있다. 다양한 자료구조가 인덱스로 고려될 수 있지만, 현재 대부분의 관계형 데이터베이스 시스템은 B-트리(B-Tree) 계열의 자료구조를 인덱스로 활용한다. 왜 B-트리 계열이 데이터베이스 인덱스로 주로 사용되는지 자세히 살펴보겠다. 여기서 B-트리 계열은 B+ 트리, B\* 트리 등 B-트리를 확장하거나 변형한 모든 트리를 포함한다.

### 1. B-트리와 다른 트리의 시간 복잡도 비교

먼저 B-트리 계열과 다른 트리의 시간 복잡도를 비교하면 흥미로운 점을 발견할 수 있다. 데이터를 조회, 삽입, 삭제하는 경우에 대해 B-트리 계열의 시간 복잡도는 평균 및 최악의 경우 모두 **O(log n)**이다.

이러한 O(log n)의 시간 복잡도는 스스로 균형을 잡는 이진 탐색 트리(Self-balancing Binary Search Tree)인 AVL 트리나 레드-블랙 트리와 동일하다. AVL 트리와 레드-블랙 트리는 이진 탐색 트리가 한쪽으로 기울어져 시간 복잡도가 O(n)으로 나빠지는 것을 보완하기 위해 스스로 균형을 맞추도록 설계된 자료구조다. 그렇다면 시간 복잡도가 동일함에도 불구하고 왜 B-트리 계열이 데이터베이스 인덱스로 더 선호되는지 의문이 들 수 있다. 이 질문에 답하기 위해서는 컴퓨터 시스템의 구조를 이해해야 한다.

### 2. 컴퓨터 시스템 구성 및 보조 기억 장치(Secondary Storage)의 특징

컴퓨터 시스템은 크게 CPU, 메인 메모리(RAM), 그리고 보조 기억 장치(Secondary Storage)로 구성된다.

- **CPU**: 프로그램 코드가 실제로 실행되는 곳이다.
- **메인 메모리 (RAM)**: 현재 실행 중인 프로그램의 코드와 데이터가 임시로 상주하는 곳이다. 흔히 램(RAM)이라 불리며, 전원이 공급되는 동안에만 데이터를 기억하는 휘발성 메모리다. 메인 메모리는 보조 기억 장치보다 **데이터 처리 속도가 훨씬 빠르지만**, 용량이 상대적으로 작다는 특징이 있다.
- **보조 기억 장치 (Secondary Storage)**: 프로그램과 데이터가 **영구적으로 저장되는 곳**이다. 컴퓨터를 껐다가 켜도 데이터가 남아 있는 비휘발성 메모리다. 하드 디스크 드라이브(HDD)나 솔리드 스테이트 드라이브(SSD)가 대표적이다.
  - **가장 느린 데이터 처리 속도**: 보조 기억 장치는 컴퓨터 시스템에서 데이터를 처리하는 속도가 가장 느리다. 예를 들어, RAM이 초당 40~50GB를 처리할 때, SSD는 초당 3~5GB, HDD는 초당 0.2~0.3GB를 처리한다. 특히 HDD는 물리적인 장치의 움직임 때문에 속도가 더욱 느리다.
  - **가장 큰 저장 용량**: 메인 메모리에 비해 훨씬 큰 용량을 가진다.
  - **블록(Block) 단위 데이터 읽기/쓰기**: 보조 기억 장치는 데이터를 읽거나 쓸 때 **블록 단위**로 동작한다. 블록은 파일 시스템이 데이터를 읽고 쓰는 논리적인 단위로, 일반적으로 4KB, 8KB, 1MB 등의 크기를 가진다. 특정 데이터 하나만 필요하더라도 해당 데이터가 포함된 블록 전체를 메인 메모리로 읽어와야 한다. 이는 한 번에 여러 데이터를 효율적으로 처리하기 위함이지만, 필요 없는 데이터까지 함께 읽어올 수 있다는 단점도 있다.

데이터베이스는 서비스 운영에 필수적인 데이터를 저장하기 때문에 **영구적인 저장이 가능한 보조 기억 장치에 저장된다**. 또한 데이터베이스의 크기는 계속해서 커지므로 용량이 큰 보조 기억 장치를 사용하는 것이 합리적이다. 데이터베이스 시스템은 핵심 데이터를 메인 메모리에 올려놓고 나머지 데이터를 보조 기억 장치에 저장한다. 외부에서 데이터 조회 요청이 들어오면, 필요한 데이터를 블록 단위로 보조 기억 장치에서 읽어와 메인 메모리에 올린 후 처리한다.

이러한 맥락에서 데이터베이스 성능에 있어 가장 중요한 포인트 중 하나는 **보조 기억 장치에 접근하는 횟수를 최소화하는 것**이다. 보조 기억 장치 접근은 메인 메모리 접근에 비해 압도적으로 느리기 때문이다.

### 3. B-트리가 보조 기억 장치 접근 횟수를 줄이는 방식

이제 B-트리가 왜 데이터베이스 인덱스로 적합한지 구체적인 예시를 통해 살펴보겠다. 동일한 조건에서 AVL 트리와 5차 B-트리 기반의 인덱스를 비교한다.

**비교 조건**:

- 인덱스 트리의 각 노드는 서로 다른 블록에 저장되어 있다고 가정한다.
- 초기에는 루트 노드만 메인 메모리에 있고, 나머지 노드와 실제 데이터는 보조 기억 장치에 저장되어 있다고 가정한다.
- 'B' 컬럼 값이 5인 데이터를 조회하는 상황을 가정한다.

#### 3.1. AVL 트리 기반 인덱스 조회 과정

AVL 트리는 각 노드가 최대 2개의 자식 노드만 가질 수 있으며, 각 노드에는 하나의 키(데이터)만 저장된다.

'B' 컬럼 값이 5인 데이터를 조회할 때, AVL 트리 기반 인덱스는 다음과 같은 단계를 거친다:

1.  루트 노드(메인 메모리)에서 탐색 시작.
2.  첫 번째 자식 노드를 읽기 위해 보조 기억 장치 접근 (1회). 해당 노드를 메인 메모리에 올린다.
3.  두 번째 자식 노드를 읽기 위해 보조 기억 장치 접근 (2회). 해당 노드를 메인 메모리에 올린다.
4.  세 번째 자식 노드(키 5를 포함)를 읽기 위해 보조 기억 장치 접근 (3회). 해당 노드를 메인 메모리에 올린다.
5.  키 5를 찾았으므로, 해당 데이터 포인터가 가리키는 실제 데이터를 읽기 위해 보조 기억 장치 접근 (4회).
    **결과: 총 4번의 보조 기억 장치 접근**.

AVL 트리는 데이터를 찾기 위해 **탐색 범위를 1/2씩 줄여나간다**. 이는 루트 노드에서 리프 노드까지의 거리가 상대적으로 길어지는 결과를 낳는다.

#### 3.2. 5차 B-트리 기반 인덱스 조회 과정

5차 B-트리(Order 5 B-Tree)는 각 노드가 최소 3개에서 최대 5개의 자식 노드를 가질 수 있으며, 각 노드에 최소 2개에서 최대 4개의 키(데이터)를 저장할 수 있다.

'B' 컬럼 값이 5인 데이터를 조회할 때, 5차 B-트리 기반 인덱스는 다음과 같은 단계를 거친다:

1.  루트 노드(메인 메모리)에서 탐색 시작.
2.  첫 번째 자식 노드(키 5를 포함)를 읽기 위해 보조 기억 장치 접근 (1회). 해당 노드를 메인 메모리에 올린다. 노드 내에서 키 5를 찾는다.
3.  키 5를 찾았으므로, 해당 데이터 포인터가 가리키는 실제 데이터를 읽기 위해 보조 기억 장치 접근 (2회).
    **결과: 총 2번의 보조 기억 장치 접근**.

B-트리는 잔여 노드 수가 많기 때문에 **탐색 범위를 최소 1/3 (최대 1/5)까지 빠르게 줄여나갈 수 있다**. 이는 루트 노드에서 리프 노드까지의 거리를 훨씬 짧게 만든다.

#### 3.3. B-트리의 핵심 장점: 낮은 트리 높이와 블록 활용 효율성

위 비교 결과에서 알 수 있듯이, B-트리는 AVL 트리에 비해 **보조 기억 장치 접근 횟수를 현저히 줄인다**. 이는 다음과 같은 B-트리의 특징 때문이다.

- **낮은 트리 높이 (Short Tree Height)**: B-트리는 각 노드가 가질 수 있는 자식 노드의 수가 많다(차수, Order). 덕분에 데이터를 저장할 때 트리의 높이가 낮아진다. 트리의 높이가 낮다는 것은 루트 노드에서 원하는 데이터를 포함하는 리프 노드까지 도달하는 경로가 짧다는 것을 의미하며, 이는 곧 보조 기억 장치 접근 횟수가 줄어드는 것과 직결된다.
- **블록 공간 활용도 높음 (High Block Space Utilization)**: B-트리 노드는 하나의 블록에 여러 개의 키와 자식 포인터를 저장한다. 보조 기억 장치에서 데이터를 읽어올 때 블록 단위로 읽어오므로, 한 번의 디스크 접근으로 더 많은 유효한 데이터를 메인 메모리에 올릴 수 있다. 이는 필요한 데이터를 효과적으로 그룹화하여 저장함으로써 블록의 활용도를 극대화하는 방식이다. 반면 AVL 트리는 각 노드가 하나의 키만 가지므로, 한 블록을 읽어올 때 불필요한 공간을 더 많이 읽어올 가능성이 있다.

### 4. B-트리의 압도적인 데이터 저장 능력

B-트리의 강력함은 단순히 낮은 트리 높이뿐만 아니라, 그로 인해 **엄청난 양의 데이터를 효율적으로 저장하고 접근할 수 있다는 점**에서 드러난다.

예를 들어, 101차 B-트리(최대 자식 노드 101개)의 경우를 살펴보자:

- **최대 키 수**: 100개
- **최소 자식 노드 수**: 51개
- **최소 키 수**: 50개 (루트 노드는 최소 1개의 키와 2개의 자식 노드를 가질 수 있음).

이러한 101차 B-트리가 레벨 3까지(높이 3) 데이터를 가득 채웠을 때(베스트 케이스), **약 1억 개의 데이터를 저장할 수 있다**. 심지어 각 노드가 최소한의 데이터만 담는 최악의 경우에도 약 26만 개의 데이터를 저장할 수 있다. 평균적으로는 수백만에서 수천만 개의 데이터를 저장 가능하다.

이처럼 B-트리는 **단지 4개의 레벨(높이 3)만으로도 수백만, 수천만 개의 데이터를 저장**할 수 있다. 이는 루트 노드에서 가장 멀리 있는 리프 노드의 데이터까지도 **세 번의 이동만으로 접근**할 수 있다는 의미다. 이로 인해 보조 기억 장치 접근 횟수를 극적으로 줄여 성능 면에서 막대한 이점을 가져다준다.

### 5. 다른 인덱스 자료구조에 대한 고려

- **스스로 균형을 잡는 이진 탐색 트리 (AVL, 레드-블랙 트리)**: 이 트리의 노드들을 블록 안에 최대한 담으려 노력하는 것은 결국 B-트리의 동작 방식과 유사해진다. 굳이 AVL 트리를 보조 기억 장치에 최적화하려 하기보다 처음부터 보조 기억 장치에 최적화된 B-트리를 사용하는 것이 더 합리적이다.
- **해시 인덱스 (Hash Index)**: 해시 인덱스는 등가 비교(equality) 조회에 있어 성능 이점을 제공하지만, **범위 기반 검색이나 정렬에는 사용할 수 없다**는 치명적인 단점이 있다. 따라서 등가 조회만 필요한 특정 상황이 아니라면 일반적으로 B-트리 기반 인덱스가 더 범용적으로 사용된다.

---

데이터베이스는 기본적으로 느린 **보조 기억 장치에 저장**되고, 데이터 처리 시 **블록 단위로 접근**한다. 따라서 인덱스의 성능은 보조 기억 장치 접근 횟수를 얼마나 줄이느냐에 달려 있다.

B-트리 계열의 자료구조는 다음과 같은 이유로 데이터베이스 인덱스에 매우 적합하다:

- **낮은 트리 높이**: 각 노드가 많은 자식 노드를 가질 수 있어 트리의 높이가 낮아진다.
- **효율적인 블록 활용**: 한 노드에 여러 키를 저장하여 한 번의 블록 읽기로 더 많은 유효 데이터를 가져올 수 있다.

이러한 특징들 덕분에 B-트리는 대규모 데이터를 저장하는 데이터베이스에서 보조 기억 장치 접근 횟수를 최소화하여 빠른 조회 성능을 제공하며, 이것이 B-트리가 데이터베이스 인덱스로 광범위하게 사용되는 핵심적인 이유다.
